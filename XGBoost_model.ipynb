{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model - Energy Cost Prediction with Time Series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data as Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import our cleaned data\n",
    "- Set datetime column as index\n",
    "- Convert our index to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/prepared/df_energy_climate_2020.csv')\n",
    "df = df.set_index('datetime')\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize our data - Energy Price Transition in 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['energy_price'].plot(\n",
    "    style='.', \n",
    "    figsize=(15, 5),\n",
    "    color=color_pal[0], # type: ignore\n",
    "    title='Energy price in 2020'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data into Train : Test = 8 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_point = (int(len(df)*0.2))\n",
    "train, test = df[:-splitting_point], df[-splitting_point:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Train / Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(15, 5))\n",
    "train.plot(ax=ax, y='energy_price', label = 'Training Set', title='Data Train/Test Split')\n",
    "test.plot(ax=ax, y='energy_price', label = 'Testing Set')\n",
    "ax.axvline('2020-10-19', color='black', ls='--') # type: ignore\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[-splitting_point]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data of one week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.index > '2020-11-01') & (df.index < '2020-11-08')]['energy_price'].plot(figsize=(15,5), title='Week of data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set our Feature and Target\n",
    "- Target = Energy price\n",
    "- Features = Hour, Day of Week, Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['hour', 'dayofweek', 'month']\n",
    "TARGET = 'energy_price'\n",
    "\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state to ensure reproductivity\n",
    "reg = xgb.XGBRegressor(random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our Model and make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "        verbose=100\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Truth and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = reg.predict(X_test)\n",
    "df = df.merge(test[['prediction']], how='left', left_index=True, right_index=True)\n",
    "ax = df[['energy_price']].plot(figsize=(15, 5))\n",
    "df['prediction'].plot(ax=ax, style='.')\n",
    "plt.legend(['Truth Data', 'Predictions'])\n",
    "ax.set_title('Raw Data and Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.loc[(df.index > '2020-11-01') & (df.index < '2020-11-08')]['energy_price'].plot(figsize=(15,5), title='Week of data')\n",
    "df.loc[(df.index > '2020-11-01') & (df.index < '2020-11-08')]['prediction'].plot(ax=ax, style='.')\n",
    "plt.legend(['Truth Data', 'Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our Model\n",
    "- We use two evaluation metrics\n",
    "    - RMSE \n",
    "    - MAPE\n",
    "\n",
    "- RMSE (Root Mean Squared Error)\n",
    "    - Measures the average distance between the predicted values and the actual values (squared difference is taking into account)\n",
    "    - RMSE gives more weight to **larger errors** and is useful when it is important to minimize the impact of large errors\n",
    "    - It can be heavily influenced by outliers\n",
    "    - Useful when comparing the performance of different models\n",
    "    - It is not always easy to interpret the magnitude of the error as it is not a percentage\n",
    "- MAPE (Mean Absolute Percentae Error)\n",
    "    - Measures the average percentage difference between the predicted values and actual values\n",
    "    - Useful when the data contains different scales or magnitudes, as it normalizes the error by the actual value\n",
    "    - It is more interpretable\n",
    "    - It may be undefined or produce very large values when the actual values are close to zero\n",
    "    - It is not symmetric => The errors in the predicted values may not be weighted equally in both directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rmse = np.sqrt(mean_squared_error(test['energy_price'], test['prediction']))\n",
    "print(f'RMSE Score on test set: {score_rmse:.2f}')\n",
    "score_mape = (mean_absolute_percentage_error(test['energy_price'], test['prediction']))\n",
    "print(f'MAPE Score on test set: {score_mape:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Characteristics of the model       | RMSE | MAPE |\n",
    "| --| -- | :----------------------: | :----------------------: | \n",
    "| Model 1 | XGBoost Regressor with Features Month, Day of week and Hour| 16.66 | 11.70% |           "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for hyperparameters\n",
    "\n",
    "### What are hyperparameters?\n",
    "- They re not lerned by the model during the training but set beforehand by the user or the researcher\n",
    "- They can have a significant impact on the performance of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_hyper_p = xgb.XGBRegressor(random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use grid search\n",
    "- We search for the best parameters for \n",
    "    - n_estimators: the number of trees built before taking the maximum voting or averages of predictions\n",
    "    - max_depth: the longest path between the root node and the leaf node \n",
    "    - gamma: controls minimum loss reduction required to split a node during tree construction\n",
    "    - learning_rate: used to govern the pace at which an algorithm updates or learns the values of a parameter estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of hyperparameter values to search\n",
    "search_space = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'gamma': [0.01, 0.1],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "GS = GridSearchCV(estimator = reg_hyper_p,\n",
    "                  param_grid = search_space,\n",
    "                  scoring=['r2', 'neg_root_mean_squared_error'],\n",
    "                  refit = 'r2', # type: ignore\n",
    "                  cv = 5,\n",
    "                #   verbose=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GS.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Model with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_hyper_p = xgb.XGBRegressor(\n",
    "    gamma=0.1,\n",
    "    n_estimators=500,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.01,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_hyper_p.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "        verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction_hyp'] = reg_hyper_p.predict(X_test)\n",
    "df = df.merge(test[['prediction_hyp']], how='left', left_index=True, right_index=True)\n",
    "ax = df[['energy_price']].plot(figsize=(15, 5))\n",
    "df['prediction_hyp'].plot(ax=ax, style='.')\n",
    "plt.legend(['Trueth Data', 'Predictions'])\n",
    "ax.set_title('Raw Data and Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.loc[(df.index > '2020-11-01') & (df.index < '2020-11-08')]['energy_price'].plot(figsize=(15,5), title='Week of data')\n",
    "df.loc[(df.index > '2020-11-01') & (df.index < '2020-11-08')]['prediction_hyp'].plot(ax=ax, style='.')\n",
    "plt.legend(['Truth Data', 'Prediction with Hyperparameters'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rmse = np.sqrt(mean_squared_error(test['energy_price'], test['prediction_hyp']))\n",
    "print(f'RMSE Score on test set: {score_rmse:.2f}')\n",
    "score_mape = (mean_absolute_percentage_error(test['energy_price'], test['prediction_hyp']))\n",
    "print(f'MAPE Score on test set: {score_mape:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Characteristics of the model       | RMSE | MAPE |\n",
    "| --| -- | :----------------------: | :----------------------: | \n",
    "| Model 1 | XGBoost Regressor with Features Month, Day of week and Hour| 16.66 | 11.70% |    \n",
    "| Model 2 | Model 1 with hyperparameters|15.89 | 12.59% |          \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE improved slightly, but MAPE worsened. What does it mean?\n",
    "This may occur when the model is accurately predicting the values close to the actual values, but making larger errors for the values that are farther from the actual values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['energy_price'].plot(kind='hist', bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('energy_price > 100').plot(y='energy_price', figsize=(15, 5), style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('energy_price < -20').plot(y='energy_price', figsize=(15, 5), style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query('energy_price < 100').copy()\n",
    "df = df.query('energy_price > -20').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_point = (int(len(df)*0.2))\n",
    "train, test = df[:-splitting_point], df[-splitting_point:]\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "reg_hyper_p.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction_less_outliers'] = reg_hyper_p.predict(X_test)\n",
    "df = df.merge(test[['prediction_less_outliers']], how='left', left_index=True, right_index=True)\n",
    "ax = df[['energy_price']].plot(figsize=(15, 5))\n",
    "df['prediction_less_outliers'].plot(ax=ax, style='.')\n",
    "plt.legend(['Truth Data', 'Predictions'])\n",
    "ax.set_title('Raw Data and Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rmse = np.sqrt(mean_squared_error(test['energy_price'], test['prediction_less_outliers']))\n",
    "print(f'RMSE Score on test set: {score_rmse:.2f}')\n",
    "score_mape = (mean_absolute_percentage_error(test['energy_price'], test['prediction_less_outliers']))\n",
    "print(f'MAPE Score on test set: {score_mape:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Characteristics of the model       | RMSE | MAPE |\n",
    "| --| -- | :----------------------: | :----------------------: | \n",
    "| Model 1 | XGBoost Regressor with Features Month, Day of week and Hour| 16.66 | 11.70% |    \n",
    "| Model 2 | Model 1 with hyperparameters|15.89 | 12.59% |               \n",
    "| Model 3 | Model 2 with data from which outliers are removed |14.24  |12.76%  | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Cross Validation\n",
    "\n",
    "### What is Cross Validation?\n",
    "Cross-validation is an essential technique used in machine learning to evaluate the performance of a model on unseen data.\n",
    "\n",
    "### Benefits of Cross Validation\n",
    "- It provides a more accurate estimate of a model's performance on new data\n",
    "- Helps to identify overfitting\n",
    "- Allows for tuning of hyperparameters to optimize model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=5, test_size=168, gap=168)\n",
    "df = df.sort_index()\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(15, 8), sharex=True)\n",
    "\n",
    "fold = 0\n",
    "preds = []\n",
    "scores_rmse = []\n",
    "scores_mape = []\n",
    "for train_idx, val_idx in tss.split(df):\n",
    "    train = df.iloc[train_idx]\n",
    "    test = df.iloc[val_idx]\n",
    "    train['energy_price'].plot(ax=axs[fold],\n",
    "                               label='Training Set',\n",
    "                               title=f'Data Train/Test Split Fold {fold}')\n",
    "    test['energy_price'].plot(ax=axs[fold],\n",
    "                              label='Test Set')\n",
    "    axs[fold].axvline(test.index.min(), color='black', ls='--')\n",
    "\n",
    "    FEATURES = ['month', 'hour', 'dayofweek']\n",
    "    TARGET = 'energy_price'\n",
    "\n",
    "    X_train = train[FEATURES]\n",
    "    y_train = train[TARGET]\n",
    "\n",
    "    X_test = test[FEATURES]\n",
    "    y_test = test[TARGET]\n",
    "\n",
    "    reg = xgb.XGBRegressor(\n",
    "        gamma=0.1,\n",
    "        n_estimators=500,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.01,\n",
    "        random_state=0\n",
    "    )\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            verbose=100)\n",
    "    \n",
    "    y_pred = reg.predict(X_test)\n",
    "    preds.append(y_pred)\n",
    "    score_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    scores_rmse.append(score_rmse)\n",
    "    score_mape = (mean_absolute_percentage_error(y_test, y_pred))\n",
    "    scores_mape.append(score_mape)\n",
    "    \n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE scores across folds {np.mean(scores_rmse):.2f}')\n",
    "print(f'Fold RMSE scores: {scores_rmse}')\n",
    "print(f'MAPE scores across folds {np.mean(scores_mape):.2f}')\n",
    "print(f'Fold MAPE scores: {scores_mape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Characteristics of the model       | RMSE | MAPE |\n",
    "| --| -- | :----------------------: | :----------------------: | \n",
    "| Model 1 | XGBoost Regressor with Features Month, Day of week and Hour| 16.66 | 11.70% |    \n",
    "| Model 2 | Model 1 with hyperparameters|15.89 | 12.59% |               \n",
    "| Model 3 | Model 2 with data from which outliers are removed |14.71  |12.66%  | \n",
    "| Model 3 | Results in Cross Validation |18.49  | 12.60% | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Cross Validation with Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_past_covariants(df, column):\n",
    "    df[f'{column}_lag1'] = df[column].shift(168)\n",
    "    df[f'{column}_lag2'] = df[column].shift(24)\n",
    "    df[f'{column}_lag3'] = df[column].shift(1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_past_covariants(df, 'energy_price')\n",
    "df = add_past_covariants(df, 'wind_speed')\n",
    "df = add_past_covariants(df, 'solar_radiation')\n",
    "df = add_past_covariants(df, 'renewable')\n",
    "df = add_past_covariants(df, 'not_renewable')\n",
    "df = add_past_covariants(df, 'nuclear_power')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take All Past Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=5, test_size=168, gap=168)\n",
    "df = df.sort_index()\n",
    "\n",
    "fold = 0\n",
    "preds = []\n",
    "scores_rmse = []\n",
    "scores_mape = []\n",
    "for train_idx, val_idx in tss.split(df):\n",
    "    train = df.iloc[train_idx]\n",
    "    test = df.iloc[val_idx]\n",
    "\n",
    "    FEATURES = ['month', 'hour', 'dayofweek', 'energy_price_lag1', 'energy_price_lag2', 'energy_price_lag3', 'wind_speed_lag1', 'wind_speed_lag2', 'wind_speed_lag3', 'solar_radiation_lag1', 'solar_radiation_lag2', 'solar_radiation_lag3', 'renewable_lag1', 'renewable_lag2', 'renewable_lag3', 'not_renewable_lag1', 'not_renewable_lag2', 'not_renewable_lag3', 'nuclear_power_lag1', 'nuclear_power_lag2', 'nuclear_power_lag3']\n",
    "    TARGET = 'energy_price'\n",
    "\n",
    "    X_train = train[FEATURES]\n",
    "    y_train = train[TARGET]\n",
    "\n",
    "    X_test = test[FEATURES]\n",
    "    y_test = test[TARGET]\n",
    "\n",
    "    reg = xgb.XGBRegressor(\n",
    "        gamma=0.1,\n",
    "        n_estimators=500,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.01,\n",
    "        random_state=0\n",
    "    )\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            verbose=100)\n",
    "    \n",
    "    y_pred = reg.predict(X_test)\n",
    "    preds.append(y_pred)\n",
    "    score_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    scores_rmse.append(score_rmse)\n",
    "    score_mape = (mean_absolute_percentage_error(y_test, y_pred))\n",
    "    scores_mape.append(score_mape)\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE scores across folds {np.mean(scores_rmse):.2f}')\n",
    "print(f'Fold RMSE scores: {scores_rmse}')\n",
    "print(f'MAPE scores across folds {np.mean(scores_mape):.2f}')\n",
    "print(f'Fold MAPE scores: {scores_mape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Characteristics of the model       | RMSE | MAPE |\n",
    "| --| -- | :----------------------: | :----------------------: | \n",
    "| Model 1 | XGBoost Regressor with Features Month, Day of week and Hour| 16.66 | 11.70% |    \n",
    "| Model 2 | Model 1 with hyperparameters|15.89 | 12.59% |               \n",
    "| Model 3 | Model 2 with data from which outliers are removed |14.71  |12.66%  | \n",
    "| Model 3 | Results in Cross Validation |16.76  | 11.91% | \n",
    "| Model 4 | Model 3 with lag features(1), results in Cross validation | 5.59  | 1.67%  | \n",
    "\n",
    "(1) Below features lagged by one week, one day and one hour are included:\n",
    "- Energy price\n",
    "- Wind speed\n",
    "- Solar radiation\n",
    "- Renewable energy feeding volume\n",
    "- Not renewable energy feeding volume\n",
    "- Nuclear energy feeding volume"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(\n",
    "    data=reg.feature_importances_,\n",
    "    index=reg.feature_names_in_,\n",
    "    columns=['importance']\n",
    ")\n",
    "fi.sort_values('importance').plot(kind='barh', title='Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Past Covariates with less Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gap: Number of samples to exclude from the end of each train set before the test set.\n",
    "tss = TimeSeriesSplit(n_splits=5, test_size=168, gap=168)\n",
    "df = df.sort_index()\n",
    "\n",
    "fold = 0\n",
    "preds = []\n",
    "scores_rmse = []\n",
    "scores_mape = []\n",
    "for train_idx, val_idx in tss.split(df):\n",
    "    train = df.iloc[train_idx]\n",
    "    test = df.iloc[val_idx]\n",
    "\n",
    "    FEATURES = ['hour', 'dayofweek', 'energy_price_lag1', 'energy_price_lag2', 'energy_price_lag3', 'solar_radiation_lag3', 'renewable_lag3', 'not_renewable_lag3']\n",
    "    TARGET = 'energy_price'\n",
    "\n",
    "    X_train = train[FEATURES]\n",
    "    y_train = train[TARGET]\n",
    "\n",
    "    X_test = test[FEATURES]\n",
    "    y_test = test[TARGET]\n",
    "\n",
    "    reg = xgb.XGBRegressor(\n",
    "        gamma=0.1,\n",
    "        n_estimators=500,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.01,\n",
    "        random_state=0\n",
    "    )\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            verbose=100)\n",
    "    \n",
    "    y_pred = reg.predict(X_test)\n",
    "    preds.append(y_pred)\n",
    "    score_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    scores_rmse.append(score_rmse)\n",
    "    score_mape = (mean_absolute_percentage_error(y_test, y_pred))\n",
    "    scores_mape.append(score_mape)\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE scores across folds {np.mean(scores_rmse):.2f}')\n",
    "print(f'Fold RMSE scores: {scores_rmse}')\n",
    "print(f'MAPE scores across folds {np.mean(scores_mape):.2f}')\n",
    "print(f'Fold MAPE scores: {scores_mape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Characteristics of the model       | RMSE | MAPE |\n",
    "| --| -- | :----------------------: | :----------------------: | \n",
    "| Model 1 | XGBoost Regressor with Features Month, Day of week and Hour| 16.66 | 11.70% |    \n",
    "| Model 2 | Model 1 with hyperparameters|15.89 | 12.59% |               \n",
    "| Model 3 | Model 2 with data from which outliers are removed |14.71  |12.66%  | \n",
    "| Model 3 | Results in Cross Validation |16.76  | 11.91% | \n",
    "| Model 4 | Model 3 with lag features(1), results in Cross validation | 5.71  | 1.71%  | \n",
    "| Model 5 | Model 3 with selected lag features(2) in Cross validation | 5.51  | 1.68%  | \n",
    "\n",
    "(1) Below features lagged by one week, one day and one hour are included:\n",
    "- Energy price\n",
    "- Wind speed\n",
    "- Solar radiation\n",
    "- Renewable energy feeding volume\n",
    "- Not renewable energy feeding volume\n",
    "- Nuclear energy feeding volume\n",
    "\n",
    "(2) Below features are included:\n",
    "- Energy price lagged by one week\n",
    "- Energy price lagged by one day\n",
    "- Energy price lagged by one hour\n",
    "- Solar radiation lagged by one hour\n",
    "- Renewable energy feeding volume lagged by one hour\n",
    "- Not renewable energy feeding volume lagged by one hour"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe\n",
    "df = pd.read_csv('./data/prepared/df_energy_climate_2020.csv')\n",
    "df = df.set_index('datetime')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Remove outliers\n",
    "df = df.query('energy_price < 105').copy()\n",
    "df = df.query('energy_price > -50').copy()\n",
    "\n",
    "one_week = 168\n",
    "\n",
    "# Add past covariants\n",
    "def add_past_covariants(df, column):\n",
    "    df[f'{column}_cov'] = df[column]\n",
    "    df.loc[(df.index >= df.index[-one_week], f'{column}_cov' )] = np.nan\n",
    "    df[f'{column}_lag1'] = df[column].shift(168)\n",
    "    df[f'{column}_lag2'] = df[column].shift(24)\n",
    "    df[f'{column}_lag3'] = df[column].shift(1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = add_past_covariants(df, 'energy_price')\n",
    "df = add_past_covariants(df, 'wind_speed')\n",
    "df = add_past_covariants(df, 'solar_radiation')\n",
    "df = add_past_covariants(df, 'renewable')\n",
    "df = add_past_covariants(df, 'not_renewable')\n",
    "df = add_past_covariants(df, 'nuclear_power')\n",
    "\n",
    "# Train / Test split\n",
    "# We use the last week of the data as test data\n",
    "train, test = df[:-one_week], df[-one_week:]\n",
    "\n",
    "# Add features and set target\n",
    "FEATURES = ['hour', 'dayofweek', 'energy_price_lag1', 'energy_price_lag2', 'energy_price_lag3', 'solar_radiation_lag3', 'renewable_lag3', 'not_renewable_lag3']\n",
    "TARGET = 'energy_price'\n",
    "\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "# Create a model\n",
    "reg = xgb.XGBRegressor(\n",
    "    gamma=0.1,\n",
    "    n_estimators=500,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.01,\n",
    "    random_state=0\n",
    ")\n",
    "reg.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "        verbose=100)\n",
    "\n",
    "# Make prediction\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "score_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "score_mape = (mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['y_pred'] = y_pred\n",
    "df = df.merge(test[['y_pred']], how='left', left_index=True, right_index=True)\n",
    "ax = df[['energy_price']].plot(figsize=(15, 5))\n",
    "df['y_pred'].plot(ax=ax, style='.')\n",
    "plt.legend(['Truth Data', 'Predictions'])\n",
    "ax.set_title('Raw Data and Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rmse = np.sqrt(mean_squared_error(test['energy_price'], test['y_pred']))\n",
    "print(f'RMSE Score on test set: {score_rmse:.2f}')\n",
    "score_mape = (mean_absolute_percentage_error(test['energy_price'], test['y_pred']))\n",
    "print(f'MAPE Score on test set: {score_mape:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Characteristics of the model       | RMSE | MAPE |\n",
    "| --| -- | :----------------------: | :----------------------: | \n",
    "| Model 1 | XGBoost Regressor with Features Month, Day of week and Hour| 16.66 | 11.70% |    \n",
    "| Model 2 | Model 1 with hyperparameters|15.89 | 12.59% |               \n",
    "| Model 3 | Model 2 with data from which outliers are removed |14.71  |12.66%  | \n",
    "| Model 3 | Results in Cross Validation |16.76  | 11.91% | \n",
    "| Model 4 | Model 3 with lag features(1), results in Cross validation | 5.71  | 1.71%  | \n",
    "| Model 5 | Model 3 with selected lag features(2) in Cross validation | 5.59  | 1.74%  | \n",
    "| Model 5 | Model 5, train : test = 51 weeks : 1 week | 4.76  | 3.13%  | \n",
    "\n",
    "(1) Below features lagged by one week, one day and one hour are included:\n",
    "- Energy price\n",
    "- Wind speed\n",
    "- Solar radiation\n",
    "- Renewable energy feeding volume\n",
    "- Not renewable energy feeding volume\n",
    "- Nuclear energy feeding volume\n",
    "\n",
    "(2) Below features are included:\n",
    "- Energy price lagged by one week\n",
    "- Energy price lagged by one day\n",
    "- Energy price lagged by one hour\n",
    "- Solar radiation lagged by one hour\n",
    "- Renewable energy feeding volume lagged by one hour\n",
    "- Not renewable energy feeding volume lagged by one hour"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model with All Data and Predict Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe\n",
    "df = pd.read_csv('./data/prepared/df_energy_climate_2020.csv')\n",
    "df = df.set_index('datetime')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Remove outliers\n",
    "df = df.query('energy_price < 100').copy()\n",
    "df = df.query('energy_price > -20').copy()\n",
    "\n",
    "# Create a dataframe for future\n",
    "future = pd.date_range('2021-01-01', '2021-01-08', freq='1h')\n",
    "future_df = pd.DataFrame(index=future)\n",
    "future_df.index = pd.to_datetime(future_df.index)\n",
    "future_df['month'] = future_df.index.month\n",
    "future_df['dayofweek'] = future_df.index.dayofweek\n",
    "future_df['hour'] = future_df.index.hour\n",
    "\n",
    "future_df['isFuture'] = True\n",
    "df['isFuture'] = False\n",
    "\n",
    "# Combine the data and future dataframe\n",
    "df_and_future = pd.concat([df, future_df])\n",
    "\n",
    "# Add past covariants\n",
    "def add_past_covariants(df, column):\n",
    "    df[f'{column}_lag1'] = df[column].shift(168)\n",
    "    df[f'{column}_lag2'] = df[column].shift(24)\n",
    "    df[f'{column}_lag3'] = df[column].shift(1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_and_future = add_past_covariants(df_and_future, 'energy_price')\n",
    "df_and_future = add_past_covariants(df_and_future, 'wind_speed')\n",
    "df_and_future = add_past_covariants(df_and_future, 'solar_radiation')\n",
    "df_and_future = add_past_covariants(df_and_future, 'renewable')\n",
    "df_and_future = add_past_covariants(df_and_future, 'not_renewable')\n",
    "df_and_future = add_past_covariants(df_and_future, 'nuclear_power')\n",
    "\n",
    "df_and_future.to_csv('./future.csv')\n",
    "\n",
    "# Extract the part for future\n",
    "future_w_features = df_and_future.query('isFuture').copy()\n",
    "\n",
    "\n",
    "# Create a model\n",
    "reg = xgb.XGBRegressor(\n",
    "    gamma=0.1,\n",
    "    n_estimators=500,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.01,\n",
    "    random_state=0\n",
    ")\n",
    "reg.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "        verbose=100)\n",
    "\n",
    "# Make prediction\n",
    "future_w_features['pred'] = reg.predict(future_w_features[FEATURES])\n",
    "\n",
    "future_w_features['pred'].plot(\n",
    "    figsize=(10, 5),\n",
    "    color='purple',\n",
    "    ms=1,\n",
    "    lw=1,\n",
    "    title= 'Future Prediction'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Techlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
